{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import xmltodict\n",
    "\n",
    "with open('/home/ray/Programming/testing/ake-datasets/datasets/ACM/test/299468.xml') as fd:\n",
    "    doc = xmltodict.parse(fd.read())\n",
    "\n",
    "File = open(' ')\n",
    "    #for sent in range(doc['root']['document']['sentences']['sentence']['@id']):\n",
    "    #    print ()\n",
    "    #    break\n",
    "    #print(doc['root']['document']['sentences']['sentence'][3]['tokens']['token'][0]['word'])\n",
    "    #print(doc['root']['document']['sentences']['sentence'][3]['tokens']['token'][0]['POS'])\n",
    "print(len(doc['root']['document']['sentences']['sentence']))\n",
    "print()\n",
    "'''\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer as Stemmer\n",
    "import regex_extraction\n",
    "import spacy_extractor\n",
    "import textrank\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n",
      "WARNING:root:Candidates are generated using 0.33-top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall for  custom_Regex is: 0.4\n",
      "recall for  spacy is: 0.32558139534883723\n",
      "recall for  textrank is: 0.1076923076923077\n"
     ]
    }
   ],
   "source": [
    "inputfiles = glob.glob(\"../data/raw/all_docs_abstacts_refined/*.txt\")\n",
    "inputfiles = [files.replace(\".txt\",\"\") for files in inputfiles]\n",
    "references_key = {}\n",
    "references_text = {}\n",
    "#inputfiles = ['1005058']\n",
    "custom_regex = []\n",
    "spacy = []\n",
    "textrank_key = []\n",
    "tp_all=[0,0,0]\n",
    "fp_all=[0,0,0]\n",
    "fn_all=[0,0,0]\n",
    "file_count =0\n",
    "for single_file in inputfiles:\n",
    "        with open(single_file + '.key', 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                keyphrases = [line.rstrip().lower() for line in lines]\n",
    "                references_key[single_file] = keyphrases\n",
    "        with open( single_file + '.txt', 'r') as f:\n",
    "                lines = f.read()\n",
    "                references_text[single_file] = lines\n",
    "        custom_regex = regex_extraction.getCandidatePhrases(references_text[single_file])\n",
    "        spacy = spacy_extractor.getCandidatePhrases(references_text[single_file])\n",
    "        textrank_key = textrank.getCandidatePhrases(references_text[single_file])\n",
    "\n",
    "        true_key = references_key[single_file]\n",
    "        true_key = [' '.join([k for k in key.split(' ') if k not in stop_words]) for key in true_key ]\n",
    "        true_key_dict = {}\n",
    "        for key in true_key:\n",
    "                true_key_dict[key] = 0\n",
    "        for i,algo in enumerate([custom_regex,spacy,textrank_key]):\n",
    "                check_key = list(algo['Keyphrase'])\n",
    "                check_key = [' '.join([k for k in key.split(' ') if k not in stop_words]) for key in check_key ]\n",
    "                tp=0\n",
    "                fp=0\n",
    "                fn=0\n",
    "                for key in check_key:\n",
    "                        if len(key.split(' '))>1:\n",
    "                                if key in true_key:\n",
    "                                        tp+=1\n",
    "                                        if true_key_dict[key] ==1:\n",
    "                                                tp-=1\n",
    "                                        else:\n",
    "                                                true_key_dict[key]=1\n",
    "                                elif any(key in word for word in true_key):\n",
    "                                        tp+=0.5\n",
    "                                else:\n",
    "                                        fp+=1\n",
    "                for key in true_key_dict.keys():\n",
    "                        if true_key_dict[key] == 0:\n",
    "                                fn+=1\n",
    "                tp_all[i]+=tp\n",
    "                fp_all[i]+=fp\n",
    "                fn_all[i]+=fn\n",
    "        file_count+=1\n",
    "        if (file_count==10):\n",
    "            break\n",
    "for i,algo in enumerate([custom_regex,spacy,textrank_key]):\n",
    "        recall = tp_all[i]/(tp_all[i]+fn_all[i])\n",
    "        print(\"recall for  \" + {0:\"custom_Regex\",1:\"spacy\",2:\"textrank\"}[i] + \" is: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:DL-wpython3]",
   "language": "python",
   "name": "conda-env-DL-wpython3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
